{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bdfccca",
   "metadata": {},
   "source": [
    "## ANALYZING CUSTOMER REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062fee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES\n",
    "import spacy                                                  # Import spaCy library\n",
    "from spacy.lang.en import English                             # Import specific model\n",
    "nlp = spacy.load(\"en_core_web_sm\")                            # Load model  \n",
    "import collections                                            # import collections \n",
    "from spacy.lang.en.stop_words import STOP_WORDS               # Importing stop words\n",
    "from spacy import displacy                                    # Import displacy for Visualizing Dependencies\n",
    "import re                                                     # Import regular expression\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38287088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198f64c",
   "metadata": {},
   "source": [
    "### PROBLEM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b52639",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=open('C:\\\\Users\\\\Admin\\\\Downloads\\\\Review1.txt').read()\n",
    "a=nlp(str(file1))\n",
    "# for token in a:\n",
    "#     print(token)\n",
    "    \n",
    "#removing stop words\n",
    "Filter1=[]\n",
    "for word in a:\n",
    "    if word.is_stop==False:\n",
    "        Filter1.append(word)\n",
    "#print('Filtered one for file1=',Filter1)\n",
    "\n",
    "#most common words\n",
    "a1=nlp(str(Filter1))\n",
    "count1=Counter()\n",
    "for token in a1:\n",
    "    count1[token.text]+=1\n",
    "m1=count1.most_common(111)\n",
    "print('Words with frequency>=40:\\n',m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d82111",
   "metadata": {},
   "source": [
    "Positive words:Almost 15 words(good,like,great,love,better,best,Great,recommend,easy,worth,interesting,wonderful,right,nice,fun)\n",
    "\n",
    "Negative words:Almost 5 words(bad,disappointed,hard,boring,problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2=open('C:\\\\Users\\\\Admin\\\\Downloads\\\\Review2.txt').read()\n",
    "b=nlp(str(file2))\n",
    "# for token in b:\n",
    "#     print(token)\n",
    "    \n",
    "#removing stop words\n",
    "Filter2=[]\n",
    "for word in b:\n",
    "    if word.is_stop==False:\n",
    "        Filter2.append(word)\n",
    "#print('Filtered one for file2=',Filter2)\n",
    "\n",
    "#most common words\n",
    "b1=nlp(str(Filter2))\n",
    "count2=Counter()\n",
    "for token in b1:\n",
    "    count2[token.text]+=1\n",
    "m2=count2.most_common(100)\n",
    "print('Words with frequency>=40:\\n',m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd18c0",
   "metadata": {},
   "source": [
    "Positive words:Almost 13 words(great,like,good,love,better,Great,best,easy,recommend,fun,right,Good,worth)\n",
    "\n",
    "Negative words:Almost 4 words(trash,bad,problem,waste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3=open('C:\\\\Users\\\\Admin\\\\Downloads\\\\Review3.txt').read()\n",
    "c=nlp(str(file3))\n",
    "# for token in c:\n",
    "#     print(token)\n",
    "    \n",
    "#removing stop words\n",
    "Filter3=[]\n",
    "for word in c:\n",
    "    if word.is_stop==False:\n",
    "        Filter3.append(word)\n",
    "#print('Filtered one for file3=',Filter3)\n",
    "\n",
    "#most common words\n",
    "c1=nlp(str(Filter3))\n",
    "count3=Counter()\n",
    "for token in c1:\n",
    "    count3[token.text]+=1\n",
    "m3=count3.most_common(98)\n",
    "print('Words with frequency>=40:\\n',m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa50195",
   "metadata": {},
   "source": [
    "Positive words:Almost 15 words(like,great,good,better,best,love,recommend,worth,Great,easy,Good,right,nice,excellent,fun)\n",
    "\n",
    "Negative words:Almost 4 words(bad,hard,disappointed,waste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8bd811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The text file with minimum data bias is Review2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36e58f4",
   "metadata": {},
   "source": [
    "### PROBLEM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('C:\\\\Users\\\\Admin\\\\Downloads\\\\Review2.txt','r').read()\n",
    "#TASK 3\n",
    "fi=re.sub('[...|$|_|.|:|!|-|?|~|(|)|%|;|\"|&|,|####|+]','',f)\n",
    "f1=nlp(fi)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy                                                  # Import spaCy library\n",
    "from spacy.lang.en import English                             # Import specific model\n",
    "nlp = spacy.load(\"en_core_web_sm\")  \n",
    "from collections import Counter\n",
    "#TASK 2  & 4 \n",
    "#REMOVING THE  WORDS-adding in default stop words\n",
    "nlp.Defaults.stop_words |= {\"ingredients\",\"live\",\"person\",\"went\",\"came\",\"gave\",\"seen\",\"movie\",\"label1\",\"label2\",\"--\",\"-\"}         \n",
    "#print(nlp.Defaults.stop_words)       \n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS \n",
    "print('Number of stop words: %d' % len(spacy_stopwords))  \n",
    "#TASK 1\n",
    "#REMOVING STOP WORDS\n",
    "Filtered=[]                                                                                                               \n",
    "for word in f1:                                                         \n",
    "    if word.is_stop==False:                                             \n",
    "        Filtered.append(word)  \n",
    "print('Count of words without stop words:',len(Filtered))\n",
    "print(\"\\nFiltered Sentence:\\n\",Filtered)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 5\n",
    "#LEMMATIZATION\n",
    "for word in Filtered:                                      \n",
    "    print(word.text,word.lemma_)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1091682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 6\n",
    "#POS TAGGING\n",
    "for word in Filtered:                                                                 \n",
    "    print(word.text,'\\t',word.pos_,'\\t',word.tag_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 7\n",
    "#NER\n",
    "Filtered=nlp(str(Filtered))\n",
    "for ent in Filtered.ents:\n",
    "    print(ent.text, '\\tstart=',ent.start_char, '\\tend=',ent.end_char, '\\tLabel=',ent.label_)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 8\n",
    "#VISUALIZE DEPENDENCIES for raw data                                 \n",
    "displacy.render(f1, style=\"dep\", jupyter= True)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 9\n",
    "#MACHINE READABLE FORMAT-word vector representation\n",
    "for token in f1:\n",
    "    print('Vector Length:\\n',token.vector.shape)                       \n",
    "    print('Word Vector Representation:\\n',token.vector)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48df901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
